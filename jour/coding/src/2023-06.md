CUDA

While reading the books, it seems really easy to understand how to structure the
Cuda c program, especially the number of threads in a block and number of
blocks. Also how to reuse shared memory and how to aggregate all the results
with paying the contention cost.

Few things I can try to learn more
1. Hands on and try on GPU instance (AWS).
2. Read Pytorch code for some operation like matmul.

It is worth to mention that, with H100 and quantization, Cuda has advanced a
lot, I properly should read all details faster.
